{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "norm_reviews = np.load('normalized_reviews.npy')\n",
    "norm_sentiment = np.load('normalized_sentiment.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (50000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(norm_sentiment.shape,norm_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     2     52      7      4     72  17965     35   3046     16     53\n",
      "   2645    124    180  12965   1946     85    773     34  12769      6\n",
      "     43     36    252      5     23     41     18   2800    106   1583\n",
      "     21      1      1      1     62    877     16   1873    289     63\n",
      "  12965     19     51  13159      9  45659   3472      7    718      5\n",
      "     46    212     10    252     29      4   1392    246      6   1857\n",
      "    289      5     41     18     40     11    277     14      4  17177\n",
      "  21364     50  25444      6     41    277  11114     88  14775     21\n",
      "   9485      8   1607      5   1743     50    718      6     51     18\n",
      "  16361      5     10      4   2396    238      7      4      1      1\n",
      "      1     18    179  12965     23     16     18      4   7402    458\n",
      "      8      4  17868   2968    198     96      1      6     24   6549\n",
      "   1678     17  19724    119      5     33   6126   1523      7      4\n",
      "   1001    115     68      4   2778     37   2851  11278      9    625\n",
      "  67375      5    104   5314     18     40    156     17      4   2808\n",
      "      6  23612    119     18    167      8    113      1  86437      5\n",
      "   2483      5 146506      5  15547      5   4995      5   8597      5\n",
      "   1842      9     60   6942    104  31999      5    340  31661      5\n",
      "  59477   9608      9  18399   3210     36    336    376      1      1\n",
      "      1     58    207      4    448   1578      7      4    277     18\n",
      "    449      8      4    857     16     24   1436    115     72    974\n",
      "     58     74  12252      6   4462   1926   2494   4609     14   4830\n",
      "   5814      5   4462   9920      5   4462   7200    438  12965    264\n",
      "     74   7566    208      6      4     62   1946     45    665    826\n",
      "   1873    289     23    104  10768     24     19  17663      5     45\n",
      "     98     74    207     45     19   1192]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(norm_reviews[0])\n",
    "print(norm_sentiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\py37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "python 3.7\n",
    "bcolz              1.2.1\n",
    "numpy              1.21.5\n",
    "pytorch  1.11.0\n",
    "\n",
    "'''\n",
    "import os\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "def pretrained_word_embeddings(embed_path:str, over_writte:bool, special_tk:bool=True, freeze:bool=True):\n",
    "    ''' return a torch.nn.Embedding layer, utilizing the pre-trained word vector (e.g., Glove), add 'bos', 'eos', 'unk' and 'pad'.\n",
    "\n",
    "    :param embed_path: the path where pre-trained matrix cached (e.g., './glove.6B.300d.txt').\n",
    "    :param over_writte: force to rewritte the existing matrix.\n",
    "    :param special_tk: whether adding special token -- 'pad', 'unk', bos' and 'eos', at position 0, 1, 2 and 3 by default.\n",
    "    :param freeze: whether trainable.\n",
    "    :return: embed -> nn.Embedding, weights_matrix -> np.array, word2idx -> function, idx2word -> function, embed_dim -> int\n",
    "    '''\n",
    "    root_dir = embed_path.rsplit(\".\",1)[0]+\".dat\"\n",
    "    out_dir_word = embed_path.rsplit(\".\",1)[0]+\"_words.pkl\"\n",
    "    out_dir_idx = embed_path.rsplit(\".\",1)[0]+\"_idx.pkl\"\n",
    "    out_dir_idx2word = embed_path.rsplit(\".\", 1)[0] + \"_idx2word.pkl\"\n",
    "    if not all([os.path.exists(root_dir),os.path.exists(out_dir_word),os.path.exists(out_dir_idx)]) or over_writte:\n",
    "        ## process and cache glove ===========================================\n",
    "        words = []\n",
    "        idx = 0\n",
    "        _word2idx = {}\n",
    "        _idx2word = {}\n",
    "        vectors = bcolz.carray(np.zeros(1), rootdir=root_dir, mode='w')\n",
    "        with open(os.path.join(embed_path),\"rb\") as f:\n",
    "            for l in f:\n",
    "                line = l.decode().split()\n",
    "                word = line[0]\n",
    "                words.append(word)\n",
    "                _word2idx[word] = idx\n",
    "                _idx2word[idx]=word\n",
    "                idx += 1\n",
    "                vect = np.array(line[1:]).astype(float)\n",
    "                vectors.append(vect)\n",
    "        vectors = bcolz.carray(vectors[1:].reshape((idx, vect.shape[0])), rootdir=root_dir, mode='w')\n",
    "        vectors.flush()\n",
    "        pickle.dump(words, open(out_dir_word, 'wb'))\n",
    "        pickle.dump(_word2idx, open(out_dir_idx, 'wb'))\n",
    "        pickle.dump(_idx2word,open(out_dir_idx2word,'wb'))\n",
    "        print(\"dump word/idx at {}\".format(embed_path.rsplit(\"/\",1)[0]))\n",
    "        ## =======================================================\n",
    "    ## load glove\n",
    "    vectors = bcolz.open(root_dir)[:]\n",
    "    words = pickle.load(open(embed_path.rsplit(\".\",1)[0]+\"_words.pkl\", 'rb'))\n",
    "    _word2idx = pickle.load(open(embed_path.rsplit(\".\",1)[0]+\"_idx.pkl\", 'rb'))\n",
    "    _idx2word=pickle.load(open(embed_path.rsplit(\".\", 1)[0] + \"_idx2word.pkl\",'rb'))\n",
    "    print(\"Successfully load Golve from {}, the shape of cached matrix: {}\".format(embed_path.rsplit(\"/\",1)[0],vectors.shape))\n",
    "\n",
    "    word_num, embed_dim = vectors.shape\n",
    "    word_num += 4  if special_tk else 0  ## e.g., 400004\n",
    "    embedding_matrix = np.zeros((word_num, embed_dim))\n",
    "    if special_tk:\n",
    "        embedding_matrix[1] = np.random.normal(scale=0.6, size=(embed_dim, ))\n",
    "        embedding_matrix[2] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
    "        embedding_matrix[3] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
    "        embedding_matrix[4:,:] = vectors\n",
    "        weights_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "        pad_idx,unk_idx, bos_idx,eos_idx = 0,1,2,3\n",
    "        embed_layer= torch.nn.Embedding.from_pretrained(weights_matrix_tensor,freeze=freeze,padding_idx=pad_idx)\n",
    "        _word2idx = dict([(k,v+4) for k,v in _word2idx.items()])\n",
    "        _idx2word = dict([(k+4,v) for k,v in _idx2word.items()])\n",
    "        assert len(_word2idx) + 4 == embedding_matrix.shape[0]\n",
    "    else:\n",
    "        embedding_matrix[:,:] = vectors\n",
    "        weights_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "        embed_layer = torch.nn.Embedding.from_pretrained(weights_matrix_tensor,freeze=freeze)\n",
    "        assert len(_word2idx) == embedding_matrix.shape[0]\n",
    "\n",
    "    def word2idx(word:str):\n",
    "        if word == '<pad>': return 0\n",
    "        elif word == '<bos>': return 2\n",
    "        elif word == '<eos>': return 3\n",
    "        return _word2idx.get(word,1)\n",
    "    def idx2word(idx:int):\n",
    "        if idx == 0: return '<pad>'\n",
    "        elif idx == 1: return '<unk>'\n",
    "        elif idx == 2: return '<bos>'\n",
    "        elif idx == 3: return '<eos>'\n",
    "        return _idx2word.get(idx,'')\n",
    "    return embed_layer, embedding_matrix, word2idx,idx2word, embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump word/idx at ../../word embeddings\n",
      "Successfully load Golve from ../../word embeddings, the shape of cached matrix: (400000, 300)\n"
     ]
    }
   ],
   "source": [
    "embed_layer, embedding_matrix, word2idx,idx2word, embed_dim = pretrained_word_embeddings('../../word embeddings/glove.6B.300d.txt',over_writte=True,special_tk=True,freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(embed_layer.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_layers,\n",
    "                 bidirectional, dropout):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = embed_layer\n",
    "        self.rnn =  nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout,batch_first=True)\n",
    "        D = 2 if bidirectional else 1\n",
    "        self.fc3 = nn.Linear(D*n_layers*hidden_dim,1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                     # 32,256,50\n",
    "        _,(hns,cells) = self.rnn(x)               # D*num_layer,batch size,hidden dim\n",
    "        x = hns.view(hns.size()[1],-1)            # reshape to 32,-1\n",
    "        # x = self.dropout(x)\n",
    "        outprob = torch.sigmoid(self.fc3(x))      # batch_size, 1\n",
    "        return outprob.view(outprob.size()[0])    # reshape to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 创建网络模型\n",
    "myModel = MyModel(300,32,2,True,0.8)\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(myModel.parameters(),0.0001)\n",
    "\n",
    "# 训练的轮数\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MyModel                                  --\n",
       "├─Embedding: 1-1                         (120,001,200)\n",
       "├─LSTM: 1-2                              110,592\n",
       "├─Linear: 1-3                            129\n",
       "├─Dropout: 1-4                           --\n",
       "=================================================================\n",
       "Total params: 120,111,921\n",
       "Trainable params: 110,721\n",
       "Non-trainable params: 120,001,200\n",
       "================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(myModel.embedding.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_num(vec1,vec2):\n",
    "    result = (torch.abs(vec1-vec2)) <0.5\n",
    "    return torch.sum(result).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class myDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(myDataset,self).__init__()\n",
    "        self.review_list = norm_reviews\n",
    "        self.label_list = norm_sentiment\n",
    "    def __getitem__(self,idx):\n",
    "        return  self.review_list[idx],self.label_list[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     2,     45,    808,     41,     19,     11,   5209,    183,\n",
       "             8,   2029,     83,     17,     11,    321,   1631,    744,\n",
       "          1179,      5,   2999,     10,      4,    329,  17113,   2252,\n",
       "             9,   2645,     11,    901,     15,  21364,   2845,      6,\n",
       "             4,   2223,     18,  26888,      5,     38,      4,   2473,\n",
       "            18,  18222,      9,      4,   2157,     36,  26081,     27,\n",
       "           155,      4,    147,   5876,   1606,   7270,   4902,     28,\n",
       "             6,    114,     81,    111,     34,   4258,     65,     43,\n",
       "          4227,     41,     18,     40,    554,    393,    236,     49,\n",
       "          1122,  10437,      5,     45,    808,     24,     19,   4299,\n",
       "            16,  10971,   3192,     18,    153,   1861,     10,    428,\n",
       "             7,      4,   1139,    113,      7,     99,     37,   2850,\n",
       "             8,      1,      1,      1,     19,      4,    100,     45,\n",
       "          1155,  11391,     26,     52,      7,  10971,     13,  15406,\n",
       "            10,     86,     27,  12252,     45,    207,     11,   1656,\n",
       "           192,     28,      6,    114,     45,    466,    336,     55,\n",
       "          6064,     21,  17046,  74977,      5,     10,     41,     71,\n",
       "          1768,      8,   4449,    139,     75,     12,  11875,     12,\n",
       "          1963,      9,   3454,    252,     79,     11,    645,      5,\n",
       "            38,  12737,    465,      1,      1,      1,    111,     40,\n",
       "            34,      4,   3124,  14145,      7,     30,    436,      5,\n",
       "            38,     24,     19, 194149,     77,     12,   6701,   9321,\n",
       "         20985,     12,      9,     60,   4005,     77,     12,  12749,\n",
       "            12,     11,    357,   2845,      8,    246,    257,     21,\n",
       "          1099,      6,      3,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=myDataset()\n",
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def myfunc(batch_data):\n",
    "    '''\n",
    "    batch_data: 32x2\n",
    "    '''\n",
    "    resData = []\n",
    "    resLabel = []\n",
    "    for i in batch_data:\n",
    "        resData.append(i[0])\n",
    "        resLabel.append(i[1])\n",
    "    return torch.tensor(np.array(resData),dtype=torch.int),torch.tensor(np.array(resLabel),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(train_dataset, batch_size=32,shuffle=True,collate_fn=myfunc,drop_last=True)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=32,shuffle=True,collate_fn=myfunc,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------第 1 轮训练开始-------\n",
      "第1轮第100训练step时的loss: 0.683272659778595\n",
      "第1轮第200训练step时的loss: 0.6978166103363037\n",
      "第1轮第300训练step时的loss: 0.6883013844490051\n",
      "第1轮第400训练step时的loss: 0.687104344367981\n",
      "第1轮第500训练step时的loss: 0.6872978806495667\n",
      "第1轮第600训练step时的loss: 0.6909545063972473\n",
      "第1轮第700训练step时的loss: 0.6953219175338745\n",
      "第1轮第800训练step时的loss: 0.6951210498809814\n",
      "第1轮第900训练step时的loss: 0.6988334059715271\n",
      "第1轮第1000训练step时的loss: 0.7011764645576477\n",
      "第1轮第1100训练step时的loss: 0.6953855752944946\n",
      "第1轮第1200训练step时的loss: 0.6904981136322021\n",
      "第1轮整体测试集上的Loss: 0.6932539508128778\n",
      "第1轮整体测试集上的Accuracy: 0.4979\n",
      "-------第 2 轮训练开始-------\n",
      "第2轮第100训练step时的loss: 0.6924232244491577\n",
      "第2轮第200训练step时的loss: 0.7010735273361206\n",
      "第2轮第300训练step时的loss: 0.6920527815818787\n",
      "第2轮第400训练step时的loss: 0.6978859305381775\n",
      "第2轮第500训练step时的loss: 0.6886424422264099\n",
      "第2轮第600训练step时的loss: 0.6947436332702637\n",
      "第2轮第700训练step时的loss: 0.6953805088996887\n",
      "第2轮第800训练step时的loss: 0.6873571872711182\n",
      "第2轮第900训练step时的loss: 0.6947407722473145\n",
      "第2轮第1000训练step时的loss: 0.6919124722480774\n",
      "第2轮第1100训练step时的loss: 0.6903525590896606\n",
      "第2轮第1200训练step时的loss: 0.6918940544128418\n",
      "第2轮整体测试集上的Loss: 0.6932416631816289\n",
      "第2轮整体测试集上的Accuracy: 0.4969\n",
      "-------第 3 轮训练开始-------\n",
      "第3轮第100训练step时的loss: 0.6950767040252686\n",
      "第3轮第200训练step时的loss: 0.6982831358909607\n",
      "第3轮第300训练step时的loss: 0.6952393651008606\n",
      "第3轮第400训练step时的loss: 0.6884815692901611\n",
      "第3轮第500训练step时的loss: 0.6914705038070679\n",
      "第3轮第600训练step时的loss: 0.7007099390029907\n",
      "第3轮第700训练step时的loss: 0.6941611766815186\n",
      "第3轮第800训练step时的loss: 0.6877740621566772\n",
      "第3轮第900训练step时的loss: 0.6905243396759033\n",
      "第3轮第1000训练step时的loss: 0.6915283799171448\n",
      "第3轮第1100训练step时的loss: 0.6960887908935547\n",
      "第3轮第1200训练step时的loss: 0.6896052956581116\n",
      "第3轮整体测试集上的Loss: 0.6933210269253478\n",
      "第3轮整体测试集上的Accuracy: 0.4903\n",
      "-------第 4 轮训练开始-------\n",
      "第4轮第100训练step时的loss: 0.6947420239448547\n",
      "第4轮第200训练step时的loss: 0.6873093843460083\n",
      "第4轮第300训练step时的loss: 0.693178653717041\n",
      "第4轮第400训练step时的loss: 0.6950558423995972\n",
      "第4轮第500训练step时的loss: 0.6983003616333008\n",
      "第4轮第600训练step时的loss: 0.6926186084747314\n",
      "第4轮第700训练step时的loss: 0.6893231868743896\n",
      "第4轮第800训练step时的loss: 0.6925778985023499\n",
      "第4轮第900训练step时的loss: 0.690674901008606\n",
      "第4轮第1000训练step时的loss: 0.6896493434906006\n",
      "第4轮第1100训练step时的loss: 0.6948424577713013\n",
      "第4轮第1200训练step时的loss: 0.6967071294784546\n",
      "第4轮整体测试集上的Loss: 0.6933194177750593\n",
      "第4轮整体测试集上的Accuracy: 0.499\n",
      "-------第 5 轮训练开始-------\n",
      "第5轮第100训练step时的loss: 0.6916890740394592\n",
      "第5轮第200训练step时的loss: 0.6930117011070251\n",
      "第5轮第300训练step时的loss: 0.6941235065460205\n",
      "第5轮第400训练step时的loss: 0.6889177560806274\n",
      "第5轮第500训练step时的loss: 0.6997011303901672\n",
      "第5轮第600训练step时的loss: 0.6936500072479248\n",
      "第5轮第700训练step时的loss: 0.6987490057945251\n",
      "第5轮第800训练step时的loss: 0.6902649998664856\n",
      "第5轮第900训练step时的loss: 0.6900079846382141\n",
      "第5轮第1000训练step时的loss: 0.6920552253723145\n",
      "第5轮第1100训练step时的loss: 0.6892834305763245\n",
      "第5轮第1200训练step时的loss: 0.6980088949203491\n",
      "第5轮整体测试集上的Loss: 0.6933498181593724\n",
      "第5轮整体测试集上的Accuracy: 0.5002\n",
      "-------第 6 轮训练开始-------\n",
      "第6轮第100训练step时的loss: 0.6868895888328552\n",
      "第6轮第200训练step时的loss: 0.6922188997268677\n",
      "第6轮第300训练step时的loss: 0.6912785172462463\n",
      "第6轮第400训练step时的loss: 0.6896855235099792\n",
      "第6轮第500训练step时的loss: 0.6921111941337585\n",
      "第6轮第600训练step时的loss: 0.6989402770996094\n",
      "第6轮第700训练step时的loss: 0.6938594579696655\n",
      "第6轮第800训练step时的loss: 0.6962165236473083\n",
      "第6轮第900训练step时的loss: 0.6919590830802917\n",
      "第6轮第1000训练step时的loss: 0.6896085739135742\n",
      "第6轮第1100训练step时的loss: 0.6959931254386902\n",
      "第6轮第1200训练step时的loss: 0.6958610415458679\n",
      "第6轮整体测试集上的Loss: 0.6933306529162786\n",
      "第6轮整体测试集上的Accuracy: 0.4939\n",
      "-------第 7 轮训练开始-------\n",
      "第7轮第100训练step时的loss: 0.6930682063102722\n",
      "第7轮第200训练step时的loss: 0.6919705271720886\n",
      "第7轮第300训练step时的loss: 0.6886705160140991\n",
      "第7轮第400训练step时的loss: 0.6955668330192566\n",
      "第7轮第500训练step时的loss: 0.6929426193237305\n",
      "第7轮第600训练step时的loss: 0.692521870136261\n",
      "第7轮第700训练step时的loss: 0.6948710083961487\n",
      "第7轮第800训练step时的loss: 0.6958094239234924\n",
      "第7轮第900训练step时的loss: 0.6897898316383362\n",
      "第7轮第1000训练step时的loss: 0.6939996480941772\n",
      "第7轮第1100训练step时的loss: 0.6968077421188354\n",
      "第7轮第1200训练step时的loss: 0.6918684244155884\n",
      "第7轮整体测试集上的Loss: 0.6933619986960303\n",
      "第7轮整体测试集上的Accuracy: 0.4933\n",
      "-------第 8 轮训练开始-------\n",
      "第8轮第100训练step时的loss: 0.6912393569946289\n",
      "第8轮第200训练step时的loss: 0.7058320641517639\n",
      "第8轮第300训练step时的loss: 0.6896756291389465\n",
      "第8轮第400训练step时的loss: 0.7025765776634216\n",
      "第8轮第500训练step时的loss: 0.6973151564598083\n",
      "第8轮第600训练step时的loss: 0.6950891017913818\n",
      "第8轮第700训练step时的loss: 0.6996940970420837\n",
      "第8轮第800训练step时的loss: 0.7015920877456665\n",
      "第8轮第900训练step时的loss: 0.6942614912986755\n",
      "第8轮第1000训练step时的loss: 0.6906988620758057\n",
      "第8轮第1100训练step时的loss: 0.6935283541679382\n",
      "第8轮第1200训练step时的loss: 0.6939859986305237\n",
      "第8轮整体测试集上的Loss: 0.6933485021432623\n",
      "第8轮整体测试集上的Accuracy: 0.4967\n",
      "-------第 9 轮训练开始-------\n",
      "第9轮第100训练step时的loss: 0.6938797831535339\n",
      "第9轮第200训练step时的loss: 0.6954910755157471\n",
      "第9轮第300训练step时的loss: 0.6950929164886475\n",
      "第9轮第400训练step时的loss: 0.6868144273757935\n",
      "第9轮第500训练step时的loss: 0.6938425898551941\n",
      "第9轮第600训练step时的loss: 0.6858021020889282\n",
      "第9轮第700训练step时的loss: 0.6888574957847595\n",
      "第9轮第800训练step时的loss: 0.6976471543312073\n",
      "第9轮第900训练step时的loss: 0.6900143027305603\n",
      "第9轮第1000训练step时的loss: 0.6956665515899658\n",
      "第9轮第1100训练step时的loss: 0.6985174417495728\n",
      "第9轮第1200训练step时的loss: 0.6888149976730347\n",
      "第9轮整体测试集上的Loss: 0.6933571761872015\n",
      "第9轮整体测试集上的Accuracy: 0.4957\n",
      "-------第 10 轮训练开始-------\n",
      "第10轮第100训练step时的loss: 0.6930621862411499\n",
      "第10轮第200训练step时的loss: 0.6950604319572449\n",
      "第10轮第300训练step时的loss: 0.6945849657058716\n",
      "第10轮第400训练step时的loss: 0.6971423029899597\n",
      "第10轮第500训练step时的loss: 0.6892076730728149\n",
      "第10轮第600训练step时的loss: 0.7002847194671631\n",
      "第10轮第700训练step时的loss: 0.6941479444503784\n",
      "第10轮第800训练step时的loss: 0.6811971664428711\n",
      "第10轮第900训练step时的loss: 0.6889670491218567\n",
      "第10轮第1000训练step时的loss: 0.6961989402770996\n",
      "第10轮第1100训练step时的loss: 0.6884791851043701\n",
      "第10轮第1200训练step时的loss: 0.6917905211448669\n",
      "第10轮整体测试集上的Loss: 0.6933343372474878\n",
      "第10轮整体测试集上的Accuracy: 0.4976\n",
      "-------第 11 轮训练开始-------\n",
      "第11轮第100训练step时的loss: 0.6902710199356079\n",
      "第11轮第200训练step时的loss: 0.6940764784812927\n",
      "第11轮第300训练step时的loss: 0.6943696737289429\n",
      "第11轮第400训练step时的loss: 0.6840198636054993\n",
      "第11轮第500训练step时的loss: 0.6921762824058533\n",
      "第11轮第600训练step时的loss: 0.6860612630844116\n",
      "第11轮第700训练step时的loss: 0.6898613572120667\n",
      "第11轮第800训练step时的loss: 0.6954389810562134\n",
      "第11轮第900训练step时的loss: 0.6973491907119751\n",
      "第11轮第1000训练step时的loss: 0.7006204128265381\n",
      "第11轮第1100训练step时的loss: 0.6912063360214233\n",
      "第11轮第1200训练step时的loss: 0.6886757016181946\n",
      "第11轮整体测试集上的Loss: 0.6932948891134251\n",
      "第11轮整体测试集上的Accuracy: 0.5136\n",
      "-------第 12 轮训练开始-------\n",
      "第12轮第100训练step时的loss: 0.6927820444107056\n",
      "第12轮第200训练step时的loss: 0.692520022392273\n",
      "第12轮第300训练step时的loss: 0.6923038959503174\n",
      "第12轮第400训练step时的loss: 0.696116030216217\n",
      "第12轮第500训练step时的loss: 0.6934189200401306\n",
      "第12轮第600训练step时的loss: 0.6916311979293823\n",
      "第12轮第700训练step时的loss: 0.6865805387496948\n",
      "第12轮第800训练step时的loss: 0.6916391253471375\n",
      "第12轮第900训练step时的loss: 0.6902791261672974\n",
      "第12轮第1000训练step时的loss: 0.6941562294960022\n",
      "第12轮第1100训练step时的loss: 0.6977987289428711\n",
      "第12轮第1200训练step时的loss: 0.6945009827613831\n",
      "第12轮整体测试集上的Loss: 0.6932889968634416\n",
      "第12轮整体测试集上的Accuracy: 0.5067\n",
      "-------第 13 轮训练开始-------\n",
      "第13轮第100训练step时的loss: 0.6891298294067383\n",
      "第13轮第200训练step时的loss: 0.6936675310134888\n",
      "第13轮第300训练step时的loss: 0.6918777227401733\n",
      "第13轮第400训练step时的loss: 0.699303388595581\n",
      "第13轮第500训练step时的loss: 0.6959707140922546\n",
      "第13轮第600训练step时的loss: 0.6910104751586914\n",
      "第13轮第700训练step时的loss: 0.6927176117897034\n",
      "第13轮第800训练step时的loss: 0.6935608386993408\n",
      "第13轮第900训练step时的loss: 0.6941241025924683\n",
      "第13轮第1000训练step时的loss: 0.6873411536216736\n",
      "第13轮第1100训练step时的loss: 0.6994484066963196\n",
      "第13轮第1200训练step时的loss: 0.6898683309555054\n",
      "第13轮整体测试集上的Loss: 0.6932771559914893\n",
      "第13轮整体测试集上的Accuracy: 0.5038\n",
      "-------第 14 轮训练开始-------\n",
      "第14轮第100训练step时的loss: 0.6954187750816345\n",
      "第14轮第200训练step时的loss: 0.6973558068275452\n",
      "第14轮第300训练step时的loss: 0.691707193851471\n",
      "第14轮第400训练step时的loss: 0.6936627626419067\n",
      "第14轮第500训练step时的loss: 0.695025622844696\n",
      "第14轮第600训练step时的loss: 0.6887366771697998\n",
      "第14轮第700训练step时的loss: 0.6937301754951477\n",
      "第14轮第800训练step时的loss: 0.698360800743103\n",
      "第14轮第900训练step时的loss: 0.6937689781188965\n",
      "第14轮第1000训练step时的loss: 0.6945163607597351\n",
      "第14轮第1100训练step时的loss: 0.6932984590530396\n",
      "第14轮第1200训练step时的loss: 0.6884390711784363\n",
      "第14轮整体测试集上的Loss: 0.6932596212096048\n",
      "第14轮整体测试集上的Accuracy: 0.5016\n",
      "-------第 15 轮训练开始-------\n",
      "第15轮第100训练step时的loss: 0.6940643787384033\n",
      "第15轮第200训练step时的loss: 0.6928519010543823\n",
      "第15轮第300训练step时的loss: 0.6914124488830566\n",
      "第15轮第400训练step时的loss: 0.692758321762085\n",
      "第15轮第500训练step时的loss: 0.6907346844673157\n",
      "第15轮第600训练step时的loss: 0.6941537261009216\n",
      "第15轮第700训练step时的loss: 0.6909492015838623\n",
      "第15轮第800训练step时的loss: 0.6973922848701477\n",
      "第15轮第900训练step时的loss: 0.6935341954231262\n",
      "第15轮第1000训练step时的loss: 0.6915113925933838\n",
      "第15轮第1100训练step时的loss: 0.6920573115348816\n",
      "第15轮第1200训练step时的loss: 0.6901783347129822\n",
      "第15轮整体测试集上的Loss: 0.6932219557400443\n",
      "第15轮整体测试集上的Accuracy: 0.5132\n",
      "-------第 16 轮训练开始-------\n",
      "第16轮第100训练step时的loss: 0.6917938590049744\n",
      "第16轮第200训练step时的loss: 0.6932504177093506\n",
      "第16轮第300训练step时的loss: 0.692884087562561\n",
      "第16轮第400训练step时的loss: 0.6966809034347534\n",
      "第16轮第500训练step时的loss: 0.6884880065917969\n",
      "第16轮第600训练step时的loss: 0.690712571144104\n",
      "第16轮第700训练step时的loss: 0.6986989974975586\n",
      "第16轮第800训练step时的loss: 0.6944484114646912\n",
      "第16轮第900训练step时的loss: 0.68852299451828\n",
      "第16轮第1000训练step时的loss: 0.6954731941223145\n",
      "第16轮第1100训练step时的loss: 0.6989630460739136\n",
      "第16轮第1200训练step时的loss: 0.6961818933486938\n",
      "第16轮整体测试集上的Loss: 0.6932285106740892\n",
      "第16轮整体测试集上的Accuracy: 0.4949\n",
      "-------第 17 轮训练开始-------\n",
      "第17轮第100训练step时的loss: 0.6930080056190491\n",
      "第17轮第200训练step时的loss: 0.6934823989868164\n",
      "第17轮第300训练step时的loss: 0.6935817003250122\n",
      "第17轮第400训练step时的loss: 0.6936489343643188\n",
      "第17轮第500训练step时的loss: 0.6903388500213623\n",
      "第17轮第600训练step时的loss: 0.6975376605987549\n",
      "第17轮第700训练step时的loss: 0.6946331262588501\n",
      "第17轮第800训练step时的loss: 0.6991358399391174\n",
      "第17轮第900训练step时的loss: 0.6913063526153564\n",
      "第17轮第1000训练step时的loss: 0.6982342600822449\n",
      "第17轮第1100训练step时的loss: 0.6950134634971619\n",
      "第17轮第1200训练step时的loss: 0.696299135684967\n",
      "第17轮整体测试集上的Loss: 0.6932250537528891\n",
      "第17轮整体测试集上的Accuracy: 0.504\n",
      "-------第 18 轮训练开始-------\n",
      "第18轮第100训练step时的loss: 0.6913190484046936\n",
      "第18轮第200训练step时的loss: 0.6941590905189514\n",
      "第18轮第300训练step时的loss: 0.6977332234382629\n",
      "第18轮第400训练step时的loss: 0.6907932162284851\n",
      "第18轮第500训练step时的loss: 0.696065366268158\n",
      "第18轮第600训练step时的loss: 0.6902424097061157\n",
      "第18轮第700训练step时的loss: 0.6906790137290955\n",
      "第18轮第800训练step时的loss: 0.6984456777572632\n",
      "第18轮第900训练step时的loss: 0.6922478079795837\n",
      "第18轮第1000训练step时的loss: 0.6921184062957764\n",
      "第18轮第1100训练step时的loss: 0.6935549974441528\n",
      "第18轮第1200训练step时的loss: 0.6949600577354431\n",
      "第18轮整体测试集上的Loss: 0.6932317466923484\n",
      "第18轮整体测试集上的Accuracy: 0.4971\n",
      "-------第 19 轮训练开始-------\n",
      "第19轮第100训练step时的loss: 0.6937729716300964\n",
      "第19轮第200训练step时的loss: 0.6969161033630371\n",
      "第19轮第300训练step时的loss: 0.6926622986793518\n",
      "第19轮第400训练step时的loss: 0.6913918852806091\n",
      "第19轮第500训练step时的loss: 0.699247419834137\n",
      "第19轮第600训练step时的loss: 0.690341591835022\n",
      "第19轮第700训练step时的loss: 0.6988415718078613\n",
      "第19轮第800训练step时的loss: 0.6933663487434387\n",
      "第19轮第900训练step时的loss: 0.6950007677078247\n",
      "第19轮第1000训练step时的loss: 0.6952698826789856\n",
      "第19轮第1100训练step时的loss: 0.6915004849433899\n",
      "第19轮第1200训练step时的loss: 0.6962448358535767\n",
      "第19轮整体测试集上的Loss: 0.6932332749791473\n",
      "第19轮整体测试集上的Accuracy: 0.4997\n",
      "-------第 20 轮训练开始-------\n",
      "第20轮第100训练step时的loss: 0.6933748722076416\n",
      "第20轮第200训练step时的loss: 0.6937952637672424\n",
      "第20轮第300训练step时的loss: 0.6957186460494995\n",
      "第20轮第400训练step时的loss: 0.6949253678321838\n",
      "第20轮第500训练step时的loss: 0.6933724880218506\n",
      "第20轮第600训练step时的loss: 0.6938211917877197\n",
      "第20轮第700训练step时的loss: 0.6949635148048401\n",
      "第20轮第800训练step时的loss: 0.696357250213623\n",
      "第20轮第900训练step时的loss: 0.6960931420326233\n",
      "第20轮第1000训练step时的loss: 0.6937488317489624\n",
      "第20轮第1100训练step时的loss: 0.6945418119430542\n",
      "第20轮第1200训练step时的loss: 0.6948208808898926\n",
      "第20轮整体测试集上的Loss: 0.6932286579352923\n",
      "第20轮整体测试集上的Accuracy: 0.5086\n",
      "-------第 21 轮训练开始-------\n",
      "第21轮第100训练step时的loss: 0.6933221220970154\n",
      "第21轮第200训练step时的loss: 0.6960265636444092\n",
      "第21轮第300训练step时的loss: 0.6920973062515259\n",
      "第21轮第400训练step时的loss: 0.6904740333557129\n",
      "第21轮第500训练step时的loss: 0.6934384107589722\n",
      "第21轮第600训练step时的loss: 0.6967989206314087\n",
      "第21轮第700训练step时的loss: 0.6907111406326294\n",
      "第21轮第800训练step时的loss: 0.6906701922416687\n",
      "第21轮第900训练step时的loss: 0.6944814920425415\n",
      "第21轮第1000训练step时的loss: 0.696725606918335\n",
      "第21轮第1100训练step时的loss: 0.6931160092353821\n",
      "第21轮第1200训练step时的loss: 0.6919125318527222\n",
      "第21轮整体测试集上的Loss: 0.693225684983972\n",
      "第21轮整体测试集上的Accuracy: 0.502\n",
      "-------第 22 轮训练开始-------\n",
      "第22轮第100训练step时的loss: 0.6863749027252197\n",
      "第22轮第200训练step时的loss: 0.6954215168952942\n",
      "第22轮第300训练step时的loss: 0.698822021484375\n",
      "第22轮第400训练step时的loss: 0.6892996430397034\n",
      "第22轮第500训练step时的loss: 0.6932063102722168\n",
      "第22轮第600训练step时的loss: 0.6895963549613953\n",
      "第22轮第700训练step时的loss: 0.693382740020752\n",
      "第22轮第800训练step时的loss: 0.694281816482544\n",
      "第22轮第900训练step时的loss: 0.6846314072608948\n",
      "第22轮第1000训练step时的loss: 0.7010428309440613\n",
      "第22轮第1100训练step时的loss: 0.6935686469078064\n",
      "第22轮第1200训练step时的loss: 0.7009333372116089\n",
      "第22轮整体测试集上的Loss: 0.6932275815929844\n",
      "第22轮整体测试集上的Accuracy: 0.4989\n",
      "-------第 23 轮训练开始-------\n",
      "第23轮第100训练step时的loss: 0.6962471604347229\n",
      "第23轮第200训练step时的loss: 0.6894060373306274\n",
      "第23轮第300训练step时的loss: 0.6840437054634094\n",
      "第23轮第400训练step时的loss: 0.6989057660102844\n",
      "第23轮第500训练step时的loss: 0.6972105503082275\n",
      "第23轮第600训练step时的loss: 0.6923069357872009\n",
      "第23轮第700训练step时的loss: 0.6918091773986816\n",
      "第23轮第800训练step时的loss: 0.6888092756271362\n",
      "第23轮第900训练step时的loss: 0.6957069635391235\n",
      "第23轮第1000训练step时的loss: 0.690543532371521\n",
      "第23轮第1100训练step时的loss: 0.6939281821250916\n",
      "第23轮第1200训练step时的loss: 0.6967095136642456\n",
      "第23轮整体测试集上的Loss: 0.69322763903351\n",
      "第23轮整体测试集上的Accuracy: 0.5001\n",
      "-------第 24 轮训练开始-------\n",
      "第24轮第100训练step时的loss: 0.6944950222969055\n",
      "第24轮第200训练step时的loss: 0.6923738718032837\n",
      "第24轮第300训练step时的loss: 0.6882367134094238\n",
      "第24轮第400训练step时的loss: 0.689995288848877\n",
      "第24轮第500训练step时的loss: 0.6891157031059265\n",
      "第24轮第600训练step时的loss: 0.693984866142273\n",
      "第24轮第700训练step时的loss: 0.6916636228561401\n",
      "第24轮第800训练step时的loss: 0.6928589344024658\n",
      "第24轮第900训练step时的loss: 0.6915379762649536\n",
      "第24轮第1000训练step时的loss: 0.6977475881576538\n",
      "第24轮第1100训练step时的loss: 0.6899076700210571\n",
      "第24轮第1200训练step时的loss: 0.6914856433868408\n",
      "第24轮整体测试集上的Loss: 0.6932477712328745\n",
      "第24轮整体测试集上的Accuracy: 0.4926\n",
      "-------第 25 轮训练开始-------\n",
      "第25轮第100训练step时的loss: 0.685620903968811\n",
      "第25轮第200训练step时的loss: 0.6989935636520386\n",
      "第25轮第300训练step时的loss: 0.6901475787162781\n",
      "第25轮第400训练step时的loss: 0.6926977038383484\n",
      "第25轮第500训练step时的loss: 0.6943985223770142\n",
      "第25轮第600训练step时的loss: 0.7010814547538757\n",
      "第25轮第700训练step时的loss: 0.688963770866394\n",
      "第25轮第800训练step时的loss: 0.6928888559341431\n",
      "第25轮第900训练step时的loss: 0.6961596012115479\n",
      "第25轮第1000训练step时的loss: 0.6937315464019775\n",
      "第25轮第1100训练step时的loss: 0.6874760985374451\n",
      "第25轮第1200训练step时的loss: 0.6988875269889832\n",
      "第25轮整体测试集上的Loss: 0.6932347889435597\n",
      "第25轮整体测试集上的Accuracy: 0.5039\n",
      "-------第 26 轮训练开始-------\n",
      "第26轮第100训练step时的loss: 0.6959961652755737\n",
      "第26轮第200训练step时的loss: 0.6872062087059021\n",
      "第26轮第300训练step时的loss: 0.6910507678985596\n",
      "第26轮第400训练step时的loss: 0.690180778503418\n",
      "第26轮第500训练step时的loss: 0.6863520741462708\n",
      "第26轮第600训练step时的loss: 0.6915099024772644\n",
      "第26轮第700训练step时的loss: 0.6868240833282471\n",
      "第26轮第800训练step时的loss: 0.7009435296058655\n",
      "第26轮第900训练step时的loss: 0.6893289685249329\n",
      "第26轮第1000训练step时的loss: 0.6973118782043457\n",
      "第26轮第1100训练step时的loss: 0.6929157972335815\n",
      "第26轮第1200训练step时的loss: 0.6944663524627686\n",
      "第26轮整体测试集上的Loss: 0.6932154227070202\n",
      "第26轮整体测试集上的Accuracy: 0.5046\n",
      "-------第 27 轮训练开始-------\n",
      "第27轮第100训练step时的loss: 0.6962592601776123\n",
      "第27轮第200训练step时的loss: 0.6911795139312744\n",
      "第27轮第300训练step时的loss: 0.6976903676986694\n",
      "第27轮第400训练step时的loss: 0.6886113286018372\n",
      "第27轮第500训练step时的loss: 0.685133695602417\n",
      "第27轮第600训练step时的loss: 0.69601970911026\n",
      "第27轮第700训练step时的loss: 0.6974374651908875\n",
      "第27轮第800训练step时的loss: 0.6880919933319092\n",
      "第27轮第900训练step时的loss: 0.6805645227432251\n",
      "第27轮第1000训练step时的loss: 0.6920543313026428\n",
      "第27轮第1100训练step时的loss: 0.6877022981643677\n",
      "第27轮第1200训练step时的loss: 0.6903213858604431\n",
      "第27轮整体测试集上的Loss: 0.6932131117890816\n",
      "第27轮整体测试集上的Accuracy: 0.4965\n",
      "-------第 28 轮训练开始-------\n",
      "第28轮第100训练step时的loss: 0.7042243480682373\n",
      "第28轮第200训练step时的loss: 0.6918193697929382\n",
      "第28轮第300训练step时的loss: 0.689427375793457\n",
      "第28轮第400训练step时的loss: 0.6988387703895569\n",
      "第28轮第500训练step时的loss: 0.695749044418335\n",
      "第28轮第600训练step时的loss: 0.6878582835197449\n",
      "第28轮第700训练step时的loss: 0.6869416236877441\n",
      "第28轮第800训练step时的loss: 0.6941443085670471\n",
      "第28轮第900训练step时的loss: 0.6866351366043091\n",
      "第28轮第1000训练step时的loss: 0.6966675519943237\n",
      "第28轮第1100训练step时的loss: 0.6995663642883301\n",
      "第28轮第1200训练step时的loss: 0.7031903862953186\n",
      "第28轮整体测试集上的Loss: 0.6932162445366055\n",
      "第28轮整体测试集上的Accuracy: 0.5005\n",
      "-------第 29 轮训练开始-------\n",
      "第29轮第100训练step时的loss: 0.7047284841537476\n",
      "第29轮第200训练step时的loss: 0.6896893978118896\n",
      "第29轮第300训练step时的loss: 0.7068414688110352\n",
      "第29轮第400训练step时的loss: 0.6929583549499512\n",
      "第29轮第500训练step时的loss: 0.6990823745727539\n",
      "第29轮第600训练step时的loss: 0.6961526274681091\n",
      "第29轮第700训练step时的loss: 0.6974004507064819\n",
      "第29轮第800训练step时的loss: 0.688643217086792\n",
      "第29轮第900训练step时的loss: 0.6843884587287903\n",
      "第29轮第1000训练step时的loss: 0.7032216787338257\n",
      "第29轮第1100训练step时的loss: 0.6953192353248596\n",
      "第29轮第1200训练step时的loss: 0.6977405548095703\n",
      "第29轮整体测试集上的Loss: 0.6932108374847763\n",
      "第29轮整体测试集上的Accuracy: 0.5038\n",
      "-------第 30 轮训练开始-------\n",
      "第30轮第100训练step时的loss: 0.6812195777893066\n",
      "第30轮第200训练step时的loss: 0.6899341940879822\n",
      "第30轮第300训练step时的loss: 0.6930340528488159\n",
      "第30轮第400训练step时的loss: 0.6997144222259521\n",
      "第30轮第500训练step时的loss: 0.6875179409980774\n",
      "第30轮第600训练step时的loss: 0.6980600357055664\n",
      "第30轮第700训练step时的loss: 0.6919933557510376\n",
      "第30轮第800训练step时的loss: 0.6973057389259338\n",
      "第30轮第900训练step时的loss: 0.6914307475090027\n",
      "第30轮第1000训练step时的loss: 0.6956853866577148\n",
      "第30轮第1100训练step时的loss: 0.6961222290992737\n",
      "第30轮第1200训练step时的loss: 0.6850532293319702\n",
      "第30轮整体测试集上的Loss: 0.6931836697089876\n",
      "第30轮整体测试集上的Accuracy: 0.5116\n",
      "-------第 31 轮训练开始-------\n",
      "第31轮第100训练step时的loss: 0.703748881816864\n",
      "第31轮第200训练step时的loss: 0.6896445751190186\n",
      "第31轮第300训练step时的loss: 0.6989333629608154\n",
      "第31轮第400训练step时的loss: 0.6940004229545593\n",
      "第31轮第500训练step时的loss: 0.6974272727966309\n",
      "第31轮第600训练step时的loss: 0.6826815605163574\n",
      "第31轮第700训练step时的loss: 0.6932986378669739\n",
      "第31轮第800训练step时的loss: 0.704606294631958\n",
      "第31轮第900训练step时的loss: 0.6831341981887817\n",
      "第31轮第1000训练step时的loss: 0.6870837211608887\n",
      "第31轮第1100训练step时的loss: 0.6937084197998047\n",
      "第31轮第1200训练step时的loss: 0.698175847530365\n",
      "第31轮整体测试集上的Loss: 0.6931729446618985\n",
      "第31轮整体测试集上的Accuracy: 0.5071\n",
      "-------第 32 轮训练开始-------\n",
      "第32轮第100训练step时的loss: 0.6959366798400879\n",
      "第32轮第200训练step时的loss: 0.6912262439727783\n",
      "第32轮第300训练step时的loss: 0.6920000910758972\n",
      "第32轮第400训练step时的loss: 0.6970442533493042\n",
      "第32轮第500训练step时的loss: 0.6922621726989746\n",
      "第32轮第600训练step时的loss: 0.6849410533905029\n",
      "第32轮第700训练step时的loss: 0.6945852041244507\n",
      "第32轮第800训练step时的loss: 0.6924353837966919\n",
      "第32轮第900训练step时的loss: 0.6897031664848328\n",
      "第32轮第1000训练step时的loss: 0.689041793346405\n",
      "第32轮第1100训练step时的loss: 0.700190544128418\n",
      "第32轮第1200训练step时的loss: 0.6888347268104553\n",
      "第32轮整体测试集上的Loss: 0.693181141721419\n",
      "第32轮整体测试集上的Accuracy: 0.5007\n",
      "-------第 33 轮训练开始-------\n",
      "第33轮第100训练step时的loss: 0.6938903331756592\n",
      "第33轮第200训练step时的loss: 0.6969932913780212\n",
      "第33轮第300训练step时的loss: 0.68534916639328\n",
      "第33轮第400训练step时的loss: 0.691148579120636\n",
      "第33轮第500训练step时的loss: 0.7024417519569397\n",
      "第33轮第600训练step时的loss: 0.6964102983474731\n",
      "第33轮第700训练step时的loss: 0.6914438009262085\n",
      "第33轮第800训练step时的loss: 0.6923344135284424\n",
      "第33轮第900训练step时的loss: 0.704365611076355\n",
      "第33轮第1000训练step时的loss: 0.7038324475288391\n",
      "第33轮第1100训练step时的loss: 0.6985958814620972\n",
      "第33轮第1200训练step时的loss: 0.6965285539627075\n",
      "第33轮整体测试集上的Loss: 0.6931544354629776\n",
      "第33轮整体测试集上的Accuracy: 0.5182\n",
      "-------第 34 轮训练开始-------\n",
      "第34轮第100训练step时的loss: 0.6925989389419556\n",
      "第34轮第200训练step时的loss: 0.6850275993347168\n",
      "第34轮第300训练step时的loss: 0.6931751370429993\n",
      "第34轮第400训练step时的loss: 0.6967118978500366\n",
      "第34轮第500训练step时的loss: 0.6935036182403564\n",
      "第34轮第600训练step时的loss: 0.7015736103057861\n",
      "第34轮第700训练step时的loss: 0.6979618072509766\n",
      "第34轮第800训练step时的loss: 0.6988747119903564\n",
      "第34轮第900训练step时的loss: 0.6994416117668152\n",
      "第34轮第1000训练step时的loss: 0.6893649697303772\n",
      "第34轮第1100训练step时的loss: 0.6917599439620972\n",
      "第34轮第1200训练step时的loss: 0.6928383111953735\n",
      "第34轮整体测试集上的Loss: 0.6931530889545091\n",
      "第34轮整体测试集上的Accuracy: 0.5023\n",
      "-------第 35 轮训练开始-------\n",
      "第35轮第100训练step时的loss: 0.7003259658813477\n",
      "第35轮第200训练step时的loss: 0.6970775723457336\n",
      "第35轮第300训练step时的loss: 0.6923241019248962\n",
      "第35轮第400训练step时的loss: 0.6934840083122253\n",
      "第35轮第500训练step时的loss: 0.6904813051223755\n",
      "第35轮第600训练step时的loss: 0.7013474702835083\n",
      "第35轮第700训练step时的loss: 0.6947914958000183\n",
      "第35轮第800训练step时的loss: 0.698150098323822\n",
      "第35轮第900训练step时的loss: 0.706247091293335\n",
      "第35轮第1000训练step时的loss: 0.6989661455154419\n",
      "第35轮第1100训练step时的loss: 0.6889371275901794\n",
      "第35轮第1200训练step时的loss: 0.6930926442146301\n",
      "第35轮整体测试集上的Loss: 0.6931596933539971\n",
      "第35轮整体测试集上的Accuracy: 0.501\n",
      "-------第 36 轮训练开始-------\n",
      "第36轮第100训练step时的loss: 0.6926653981208801\n",
      "第36轮第200训练step时的loss: 0.6964396238327026\n",
      "第36轮第300训练step时的loss: 0.6902276277542114\n",
      "第36轮第400训练step时的loss: 0.6885995268821716\n",
      "第36轮第500训练step时的loss: 0.6955706477165222\n",
      "第36轮第600训练step时的loss: 0.6826707124710083\n",
      "第36轮第700训练step时的loss: 0.6892807483673096\n",
      "第36轮第800训练step时的loss: 0.6965336203575134\n",
      "第36轮第900训练step时的loss: 0.6959835290908813\n",
      "第36轮第1000训练step时的loss: 0.697318971157074\n",
      "第36轮第1100训练step时的loss: 0.6749146580696106\n",
      "第36轮第1200训练step时的loss: 0.6930100917816162\n",
      "第36轮整体测试集上的Loss: 0.6931230176685967\n",
      "第36轮整体测试集上的Accuracy: 0.5186\n",
      "-------第 37 轮训练开始-------\n",
      "第37轮第100训练step时的loss: 0.6970396041870117\n",
      "第37轮第200训练step时的loss: 0.6912217140197754\n",
      "第37轮第300训练step时的loss: 0.6968629956245422\n",
      "第37轮第400训练step时的loss: 0.6838037371635437\n",
      "第37轮第500训练step时的loss: 0.6876229047775269\n",
      "第37轮第600训练step时的loss: 0.6893497109413147\n",
      "第37轮第700训练step时的loss: 0.6843404173851013\n",
      "第37轮第800训练step时的loss: 0.6915514469146729\n",
      "第37轮第900训练step时的loss: 0.6975324153900146\n",
      "第37轮第1000训练step时的loss: 0.6872543096542358\n",
      "第37轮第1100训练step时的loss: 0.6904375553131104\n",
      "第37轮第1200训练step时的loss: 0.7008672952651978\n",
      "第37轮整体测试集上的Loss: 0.6931133312550751\n",
      "第37轮整体测试集上的Accuracy: 0.5078\n",
      "-------第 38 轮训练开始-------\n",
      "第38轮第100训练step时的loss: 0.6929771900177002\n",
      "第38轮第200训练step时的loss: 0.6861183643341064\n",
      "第38轮第300训练step时的loss: 0.6966822147369385\n",
      "第38轮第400训练step时的loss: 0.6892920136451721\n",
      "第38轮第500训练step时的loss: 0.6873220205307007\n",
      "第38轮第600训练step时的loss: 0.6926869750022888\n",
      "第38轮第700训练step时的loss: 0.6933118104934692\n",
      "第38轮第800训练step时的loss: 0.6918290257453918\n",
      "第38轮第900训练step时的loss: 0.6918851137161255\n",
      "第38轮第1000训练step时的loss: 0.6991065144538879\n",
      "第38轮第1100训练step时的loss: 0.6971453428268433\n",
      "第38轮第1200训练step时的loss: 0.6970289945602417\n",
      "第38轮整体测试集上的Loss: 0.6931195599347474\n",
      "第38轮整体测试集上的Accuracy: 0.4956\n",
      "-------第 39 轮训练开始-------\n",
      "第39轮第100训练step时的loss: 0.6978987455368042\n",
      "第39轮第200训练step时的loss: 0.6863916516304016\n",
      "第39轮第300训练step时的loss: 0.6899487972259521\n",
      "第39轮第400训练step时的loss: 0.6941180229187012\n",
      "第39轮第500训练step时的loss: 0.6886168718338013\n",
      "第39轮第600训练step时的loss: 0.6893306374549866\n",
      "第39轮第700训练step时的loss: 0.6874933242797852\n",
      "第39轮第800训练step时的loss: 0.6842969059944153\n",
      "第39轮第900训练step时的loss: 0.6950808763504028\n",
      "第39轮第1000训练step时的loss: 0.6952676177024841\n",
      "第39轮第1100训练step时的loss: 0.6919634938240051\n",
      "第39轮第1200训练step时的loss: 0.6850436925888062\n",
      "第39轮整体测试集上的Loss: 0.6931125249402607\n",
      "第39轮整体测试集上的Accuracy: 0.5096\n",
      "-------第 40 轮训练开始-------\n",
      "第40轮第100训练step时的loss: 0.6865754723548889\n",
      "第40轮第200训练step时的loss: 0.6906368136405945\n",
      "第40轮第300训练step时的loss: 0.6840240955352783\n",
      "第40轮第400训练step时的loss: 0.6883689165115356\n",
      "第40轮第500训练step时的loss: 0.6811615824699402\n",
      "第40轮第600训练step时的loss: 0.6968554258346558\n",
      "第40轮第700训练step时的loss: 0.6930615901947021\n",
      "第40轮第800训练step时的loss: 0.7002500891685486\n",
      "第40轮第900训练step时的loss: 0.6986920833587646\n",
      "第40轮第1000训练step时的loss: 0.6945992112159729\n",
      "第40轮第1100训练step时的loss: 0.6918832659721375\n",
      "第40轮第1200训练step时的loss: 0.6948456764221191\n",
      "第40轮整体测试集上的Loss: 0.693090916176637\n",
      "第40轮整体测试集上的Accuracy: 0.5168\n",
      "-------第 41 轮训练开始-------\n",
      "第41轮第100训练step时的loss: 0.6983218193054199\n",
      "第41轮第200训练step时的loss: 0.6991770267486572\n",
      "第41轮第300训练step时的loss: 0.6930922269821167\n",
      "第41轮第400训练step时的loss: 0.691928505897522\n",
      "第41轮第500训练step时的loss: 0.6900882720947266\n",
      "第41轮第600训练step时的loss: 0.6906254291534424\n",
      "第41轮第700训练step时的loss: 0.6873537302017212\n",
      "第41轮第800训练step时的loss: 0.6962007880210876\n",
      "第41轮第900训练step时的loss: 0.6939211487770081\n",
      "第41轮第1000训练step时的loss: 0.6929633617401123\n",
      "第41轮第1100训练step时的loss: 0.6905956864356995\n",
      "第41轮第1200训练step时的loss: 0.6916454434394836\n",
      "第41轮整体测试集上的Loss: 0.6930893078875064\n",
      "第41轮整体测试集上的Accuracy: 0.5034\n",
      "-------第 42 轮训练开始-------\n",
      "第42轮第100训练step时的loss: 0.6934401988983154\n",
      "第42轮第200训练step时的loss: 0.6941509246826172\n",
      "第42轮第300训练step时的loss: 0.6880086660385132\n",
      "第42轮第400训练step时的loss: 0.6934287548065186\n",
      "第42轮第500训练step时的loss: 0.6982907056808472\n",
      "第42轮第600训练step时的loss: 0.6947065591812134\n",
      "第42轮第700训练step时的loss: 0.6891135573387146\n",
      "第42轮第800训练step时的loss: 0.6846756339073181\n",
      "第42轮第900训练step时的loss: 0.6944380402565002\n",
      "第42轮第1000训练step时的loss: 0.6955413818359375\n",
      "第42轮第1100训练step时的loss: 0.694350004196167\n",
      "第42轮第1200训练step时的loss: 0.689686119556427\n",
      "第42轮整体测试集上的Loss: 0.6930877864315323\n",
      "第42轮整体测试集上的Accuracy: 0.5054\n",
      "-------第 43 轮训练开始-------\n",
      "第43轮第100训练step时的loss: 0.7037717700004578\n",
      "第43轮第200训练step时的loss: 0.6931646466255188\n",
      "第43轮第300训练step时的loss: 0.699763298034668\n",
      "第43轮第400训练step时的loss: 0.6927618980407715\n",
      "第43轮第500训练step时的loss: 0.6988297700881958\n",
      "第43轮第600训练step时的loss: 0.6885516047477722\n",
      "第43轮第700训练step时的loss: 0.6935665607452393\n",
      "第43轮第800训练step时的loss: 0.6992474794387817\n",
      "第43轮第900训练step时的loss: 0.6862764358520508\n",
      "第43轮第1000训练step时的loss: 0.6919739246368408\n",
      "第43轮第1100训练step时的loss: 0.6918065547943115\n",
      "第43轮第1200训练step时的loss: 0.6874465942382812\n",
      "第43轮整体测试集上的Loss: 0.6930855761549269\n",
      "第43轮整体测试集上的Accuracy: 0.5026\n",
      "-------第 44 轮训练开始-------\n",
      "第44轮第100训练step时的loss: 0.6985293030738831\n",
      "第44轮第200训练step时的loss: 0.6874217987060547\n",
      "第44轮第300训练step时的loss: 0.6961620450019836\n",
      "第44轮第400训练step时的loss: 0.6880372166633606\n",
      "第44轮第500训练step时的loss: 0.6879651546478271\n",
      "第44轮第600训练step时的loss: 0.6983981728553772\n",
      "第44轮第700训练step时的loss: 0.6839479207992554\n",
      "第44轮第800训练step时的loss: 0.7009421586990356\n",
      "第44轮第900训练step时的loss: 0.692431628704071\n",
      "第44轮第1000训练step时的loss: 0.6902563571929932\n",
      "第44轮第1100训练step时的loss: 0.6875559687614441\n",
      "第44轮第1200训练step时的loss: 0.6870682835578918\n",
      "第44轮整体测试集上的Loss: 0.6930840106980576\n",
      "第44轮整体测试集上的Accuracy: 0.5038\n",
      "-------第 45 轮训练开始-------\n",
      "第45轮第100训练step时的loss: 0.7011497616767883\n",
      "第45轮第200训练step时的loss: 0.6990130543708801\n",
      "第45轮第300训练step时的loss: 0.6917741298675537\n",
      "第45轮第400训练step时的loss: 0.6901136636734009\n",
      "第45轮第500训练step时的loss: 0.6877610683441162\n",
      "第45轮第600训练step时的loss: 0.6878268122673035\n",
      "第45轮第700训练step时的loss: 0.6876980066299438\n",
      "第45轮第800训练step时的loss: 0.6857254505157471\n",
      "第45轮第900训练step时的loss: 0.7024722099304199\n",
      "第45轮第1000训练step时的loss: 0.6892441511154175\n",
      "第45轮第1100训练step时的loss: 0.6883019208908081\n",
      "第45轮第1200训练step时的loss: 0.691509485244751\n",
      "第45轮整体测试集上的Loss: 0.6930654827728231\n",
      "第45轮整体测试集上的Accuracy: 0.5154\n",
      "-------第 46 轮训练开始-------\n",
      "第46轮第100训练step时的loss: 0.6863954067230225\n",
      "第46轮第200训练step时的loss: 0.6975992918014526\n",
      "第46轮第300训练step时的loss: 0.7067083120346069\n",
      "第46轮第400训练step时的loss: 0.6852419376373291\n",
      "第46轮第500训练step时的loss: 0.6978480815887451\n",
      "第46轮第600训练step时的loss: 0.6875565052032471\n",
      "第46轮第700训练step时的loss: 0.6846655011177063\n",
      "第46轮第800训练step时的loss: 0.6873481273651123\n",
      "第46轮第900训练step时的loss: 0.6916354298591614\n",
      "第46轮第1000训练step时的loss: 0.6919565200805664\n",
      "第46轮第1100训练step时的loss: 0.6964743137359619\n",
      "第46轮第1200训练step时的loss: 0.6879631876945496\n",
      "第46轮整体测试集上的Loss: 0.6930610239298115\n",
      "第46轮整体测试集上的Accuracy: 0.5059\n",
      "-------第 47 轮训练开始-------\n",
      "第47轮第100训练step时的loss: 0.697861909866333\n",
      "第47轮第200训练step时的loss: 0.7015528082847595\n",
      "第47轮第300训练step时的loss: 0.6866173148155212\n",
      "第47轮第400训练step时的loss: 0.699272096157074\n",
      "第47轮第500训练step时的loss: 0.6955828070640564\n",
      "第47轮第600训练step时的loss: 0.692040205001831\n",
      "第47轮第700训练step时的loss: 0.6943734884262085\n",
      "第47轮第800训练step时的loss: 0.6972068548202515\n",
      "第47轮第900训练step时的loss: 0.6830175518989563\n",
      "第47轮第1000训练step时的loss: 0.6909036636352539\n",
      "第47轮第1100训练step时的loss: 0.6929919719696045\n",
      "第47轮第1200训练step时的loss: 0.6892207264900208\n",
      "第47轮整体测试集上的Loss: 0.6930590024125491\n",
      "第47轮整体测试集上的Accuracy: 0.5063\n",
      "-------第 48 轮训练开始-------\n",
      "第48轮第100训练step时的loss: 0.7001438140869141\n",
      "第48轮第200训练step时的loss: 0.6919605731964111\n",
      "第48轮第300训练step时的loss: 0.6934134364128113\n",
      "第48轮第400训练step时的loss: 0.6949095129966736\n",
      "第48轮第500训练step时的loss: 0.6855283379554749\n",
      "第48轮第600训练step时的loss: 0.6966713070869446\n",
      "第48轮第700训练step时的loss: 0.6954329013824463\n",
      "第48轮第800训练step时的loss: 0.6910943984985352\n",
      "第48轮第900训练step时的loss: 0.6919146776199341\n",
      "第48轮第1000训练step时的loss: 0.6853026747703552\n",
      "第48轮第1100训练step时的loss: 0.6938467621803284\n",
      "第48轮第1200训练step时的loss: 0.68743497133255\n",
      "第48轮整体测试集上的Loss: 0.6930418684004018\n",
      "第48轮整体测试集上的Accuracy: 0.5096\n",
      "-------第 49 轮训练开始-------\n",
      "第49轮第100训练step时的loss: 0.6848150491714478\n",
      "第49轮第200训练step时的loss: 0.6847314834594727\n",
      "第49轮第300训练step时的loss: 0.6947275400161743\n",
      "第49轮第400训练step时的loss: 0.7058831453323364\n",
      "第49轮第500训练step时的loss: 0.6981142163276672\n",
      "第49轮第600训练step时的loss: 0.6928809285163879\n",
      "第49轮第700训练step时的loss: 0.6905309557914734\n",
      "第49轮第800训练step时的loss: 0.6937978267669678\n",
      "第49轮第900训练step时的loss: 0.6850621700286865\n",
      "第49轮第1000训练step时的loss: 0.6994373202323914\n",
      "第49轮第1100训练step时的loss: 0.689581036567688\n",
      "第49轮第1200训练step时的loss: 0.699246883392334\n",
      "第49轮整体测试集上的Loss: 0.693022067663964\n",
      "第49轮整体测试集上的Accuracy: 0.5195\n",
      "-------第 50 轮训练开始-------\n",
      "第50轮第100训练step时的loss: 0.6888201832771301\n",
      "第50轮第200训练step时的loss: 0.6924687027931213\n",
      "第50轮第300训练step时的loss: 0.6878921985626221\n",
      "第50轮第400训练step时的loss: 0.6941320896148682\n",
      "第50轮第500训练step时的loss: 0.6890842914581299\n",
      "第50轮第600训练step时的loss: 0.6927526593208313\n",
      "第50轮第700训练step时的loss: 0.6960791349411011\n",
      "第50轮第800训练step时的loss: 0.6984094381332397\n",
      "第50轮第900训练step时的loss: 0.696643054485321\n",
      "第50轮第1000训练step时的loss: 0.6933403611183167\n",
      "第50轮第1100训练step时的loss: 0.6977567672729492\n",
      "第50轮第1200训练step时的loss: 0.6931264996528625\n",
      "第50轮整体测试集上的Loss: 0.6930040815434395\n",
      "第50轮整体测试集上的Accuracy: 0.5146\n",
      "-------第 51 轮训练开始-------\n",
      "第51轮第100训练step时的loss: 0.6885190606117249\n",
      "第51轮第200训练step时的loss: 0.6822914481163025\n",
      "第51轮第300训练step时的loss: 0.6910300254821777\n",
      "第51轮第400训练step时的loss: 0.689332902431488\n",
      "第51轮第500训练step时的loss: 0.7063390612602234\n",
      "第51轮第600训练step时的loss: 0.6871030926704407\n",
      "第51轮第700训练step时的loss: 0.6876276731491089\n",
      "第51轮第800训练step时的loss: 0.6874911189079285\n",
      "第51轮第900训练step时的loss: 0.694230318069458\n",
      "第51轮第1000训练step时的loss: 0.6790947914123535\n",
      "第51轮第1100训练step时的loss: 0.6923805475234985\n",
      "第51轮第1200训练step时的loss: 0.6926417946815491\n",
      "第51轮整体测试集上的Loss: 0.6929901532263179\n",
      "第51轮整体测试集上的Accuracy: 0.5096\n",
      "-------第 52 轮训练开始-------\n",
      "第52轮第100训练step时的loss: 0.6825091242790222\n",
      "第52轮第200训练step时的loss: 0.6913963556289673\n",
      "第52轮第300训练step时的loss: 0.6784905195236206\n",
      "第52轮第400训练step时的loss: 0.6881898045539856\n",
      "第52轮第500训练step时的loss: 0.6925636529922485\n",
      "第52轮第600训练step时的loss: 0.6915985345840454\n",
      "第52轮第700训练step时的loss: 0.6912715435028076\n",
      "第52轮第800训练step时的loss: 0.6976427435874939\n",
      "第52轮第900训练step时的loss: 0.6955757141113281\n",
      "第52轮第1000训练step时的loss: 0.6991384625434875\n",
      "第52轮第1100训练step时的loss: 0.7030536532402039\n",
      "第52轮第1200训练step时的loss: 0.6889976263046265\n",
      "第52轮整体测试集上的Loss: 0.6929878873835066\n",
      "第52轮整体测试集上的Accuracy: 0.507\n",
      "-------第 53 轮训练开始-------\n",
      "第53轮第100训练step时的loss: 0.6921086311340332\n",
      "第53轮第200训练step时的loss: 0.6879806518554688\n",
      "第53轮第300训练step时的loss: 0.6917198896408081\n",
      "第53轮第400训练step时的loss: 0.6787563562393188\n",
      "第53轮第500训练step时的loss: 0.6872771382331848\n",
      "第53轮第600训练step时的loss: 0.6899549961090088\n",
      "第53轮第700训练step时的loss: 0.6909977793693542\n",
      "第53轮第800训练step时的loss: 0.6964912414550781\n",
      "第53轮第900训练step时的loss: 0.7003891468048096\n",
      "第53轮第1000训练step时的loss: 0.6910029649734497\n",
      "第53轮第1100训练step时的loss: 0.6813523769378662\n",
      "第53轮第1200训练step时的loss: 0.6805638670921326\n",
      "第53轮整体测试集上的Loss: 0.6929800648964946\n",
      "第53轮整体测试集上的Accuracy: 0.5117\n",
      "-------第 54 轮训练开始-------\n",
      "第54轮第100训练step时的loss: 0.7014839053153992\n",
      "第54轮第200训练step时的loss: 0.6952015161514282\n",
      "第54轮第300训练step时的loss: 0.6873354911804199\n",
      "第54轮第400训练step时的loss: 0.6978620886802673\n",
      "第54轮第500训练step时的loss: 0.6932309865951538\n",
      "第54轮第600训练step时的loss: 0.6914956569671631\n",
      "第54轮第700训练step时的loss: 0.6866244077682495\n",
      "第54轮第800训练step时的loss: 0.7028038501739502\n",
      "第54轮第900训练step时的loss: 0.6932908296585083\n",
      "第54轮第1000训练step时的loss: 0.6899673938751221\n",
      "第54轮第1100训练step时的loss: 0.6852399110794067\n",
      "第54轮第1200训练step时的loss: 0.6960216164588928\n",
      "第54轮整体测试集上的Loss: 0.692970100577995\n",
      "第54轮整体测试集上的Accuracy: 0.5065\n",
      "-------第 55 轮训练开始-------\n",
      "第55轮第100训练step时的loss: 0.6922402381896973\n",
      "第55轮第200训练step时的loss: 0.6909317374229431\n",
      "第55轮第300训练step时的loss: 0.6754156947135925\n",
      "第55轮第400训练step时的loss: 0.7047376036643982\n",
      "第55轮第500训练step时的loss: 0.6874051094055176\n",
      "第55轮第600训练step时的loss: 0.6907302141189575\n",
      "第55轮第700训练step时的loss: 0.6815769076347351\n",
      "第55轮第800训练step时的loss: 0.6933761239051819\n",
      "第55轮第900训练step时的loss: 0.6818476319313049\n",
      "第55轮第1000训练step时的loss: 0.6928002238273621\n",
      "第55轮第1100训练step时的loss: 0.6987925171852112\n",
      "第55轮第1200训练step时的loss: 0.7016662955284119\n",
      "第55轮整体测试集上的Loss: 0.6929513351935329\n",
      "第55轮整体测试集上的Accuracy: 0.5142\n",
      "-------第 56 轮训练开始-------\n",
      "第56轮第100训练step时的loss: 0.6937547922134399\n",
      "第56轮第200训练step时的loss: 0.6920207738876343\n",
      "第56轮第300训练step时的loss: 0.7125168442726135\n",
      "第56轮第400训练step时的loss: 0.6964609026908875\n",
      "第56轮第500训练step时的loss: 0.7068647146224976\n",
      "第56轮第600训练step时的loss: 0.6858745813369751\n",
      "第56轮第700训练step时的loss: 0.6933228373527527\n",
      "第56轮第800训练step时的loss: 0.6941255331039429\n",
      "第56轮第900训练step时的loss: 0.6938655376434326\n",
      "第56轮第1000训练step时的loss: 0.6967313289642334\n",
      "第56轮第1100训练step时的loss: 0.6890186667442322\n",
      "第56轮第1200训练step时的loss: 0.6877288818359375\n",
      "第56轮整体测试集上的Loss: 0.692945330052367\n",
      "第56轮整体测试集上的Accuracy: 0.5113\n",
      "-------第 57 轮训练开始-------\n",
      "第57轮第100训练step时的loss: 0.6982307434082031\n",
      "第57轮第200训练step时的loss: 0.6989412307739258\n",
      "第57轮第300训练step时的loss: 0.6972562074661255\n",
      "第57轮第400训练step时的loss: 0.7006415128707886\n",
      "第57轮第500训练step时的loss: 0.683760404586792\n",
      "第57轮第600训练step时的loss: 0.6967393159866333\n",
      "第57轮第700训练step时的loss: 0.6912633180618286\n",
      "第57轮第800训练step时的loss: 0.6883533596992493\n",
      "第57轮第900训练step时的loss: 0.7009081840515137\n",
      "第57轮第1000训练step时的loss: 0.7024880051612854\n",
      "第57轮第1100训练step时的loss: 0.6915827393531799\n",
      "第57轮第1200训练step时的loss: 0.6915301084518433\n",
      "第57轮整体测试集上的Loss: 0.6929359959486203\n",
      "第57轮整体测试集上的Accuracy: 0.5125\n",
      "-------第 58 轮训练开始-------\n",
      "第58轮第100训练step时的loss: 0.680476725101471\n",
      "第58轮第200训练step时的loss: 0.6857210397720337\n",
      "第58轮第300训练step时的loss: 0.6847379207611084\n",
      "第58轮第400训练step时的loss: 0.694189190864563\n",
      "第58轮第500训练step时的loss: 0.6860817670822144\n",
      "第58轮第600训练step时的loss: 0.6838092803955078\n",
      "第58轮第700训练step时的loss: 0.6894480586051941\n",
      "第58轮第800训练step时的loss: 0.6998222470283508\n",
      "第58轮第900训练step时的loss: 0.7005678415298462\n",
      "第58轮第1000训练step时的loss: 0.6814107298851013\n",
      "第58轮第1100训练step时的loss: 0.679601788520813\n",
      "第58轮第1200训练step时的loss: 0.6854451894760132\n",
      "第58轮整体测试集上的Loss: 0.6929503429638243\n",
      "第58轮整体测试集上的Accuracy: 0.5081\n",
      "-------第 59 轮训练开始-------\n",
      "第59轮第100训练step时的loss: 0.7077231407165527\n",
      "第59轮第200训练step时的loss: 0.6874736547470093\n",
      "第59轮第300训练step时的loss: 0.6964762210845947\n",
      "第59轮第400训练step时的loss: 0.7008619904518127\n",
      "第59轮第500训练step时的loss: 0.6917663812637329\n",
      "第59轮第600训练step时的loss: 0.6908468008041382\n",
      "第59轮第700训练step时的loss: 0.6906159520149231\n",
      "第59轮第800训练step时的loss: 0.6910426020622253\n",
      "第59轮第900训练step时的loss: 0.6934519410133362\n",
      "第59轮第1000训练step时的loss: 0.6995140910148621\n",
      "第59轮第1100训练step时的loss: 0.6929814219474792\n",
      "第59轮第1200训练step时的loss: 0.6979639530181885\n",
      "第59轮整体测试集上的Loss: 0.6929604020398733\n",
      "第59轮整体测试集上的Accuracy: 0.4991\n",
      "-------第 60 轮训练开始-------\n",
      "第60轮第100训练step时的loss: 0.6890607476234436\n",
      "第60轮第200训练step时的loss: 0.6892634630203247\n",
      "第60轮第300训练step时的loss: 0.6756850481033325\n",
      "第60轮第400训练step时的loss: 0.6842182874679565\n",
      "第60轮第500训练step时的loss: 0.6892858147621155\n",
      "第60轮第600训练step时的loss: 0.7039850354194641\n",
      "第60轮第700训练step时的loss: 0.6904224157333374\n",
      "第60轮第800训练step时的loss: 0.6989021897315979\n",
      "第60轮第900训练step时的loss: 0.6882125735282898\n",
      "第60轮第1000训练step时的loss: 0.6763124465942383\n",
      "第60轮第1100训练step时的loss: 0.6957137584686279\n",
      "第60轮第1200训练step时的loss: 0.6963136196136475\n",
      "第60轮整体测试集上的Loss: 0.6929516449889057\n",
      "第60轮整体测试集上的Accuracy: 0.5176\n",
      "-------第 61 轮训练开始-------\n",
      "第61轮第100训练step时的loss: 0.6992374658584595\n",
      "第61轮第200训练step时的loss: 0.6919146776199341\n",
      "第61轮第300训练step时的loss: 0.6950570344924927\n",
      "第61轮第400训练step时的loss: 0.688509464263916\n",
      "第61轮第500训练step时的loss: 0.6870409846305847\n",
      "第61轮第600训练step时的loss: 0.6888547539710999\n",
      "第61轮第700训练step时的loss: 0.6999950408935547\n",
      "第61轮第800训练step时的loss: 0.6918801665306091\n",
      "第61轮第900训练step时的loss: 0.6920762062072754\n",
      "第61轮第1000训练step时的loss: 0.6979336738586426\n",
      "第61轮第1100训练step时的loss: 0.6816952228546143\n",
      "第61轮第1200训练step时的loss: 0.6932975649833679\n",
      "第61轮整体测试集上的Loss: 0.6929404353452812\n",
      "第61轮整体测试集上的Accuracy: 0.5133\n",
      "-------第 62 轮训练开始-------\n",
      "第62轮第100训练step时的loss: 0.688669741153717\n",
      "第62轮第200训练step时的loss: 0.685523271560669\n",
      "第62轮第300训练step时的loss: 0.6928033828735352\n",
      "第62轮第400训练step时的loss: 0.7023718953132629\n",
      "第62轮第500训练step时的loss: 0.6858697533607483\n",
      "第62轮第600训练step时的loss: 0.7002664804458618\n",
      "第62轮第700训练step时的loss: 0.7003186941146851\n",
      "第62轮第800训练step时的loss: 0.6915687918663025\n",
      "第62轮第900训练step时的loss: 0.6956204175949097\n",
      "第62轮第1000训练step时的loss: 0.6867675185203552\n",
      "第62轮第1100训练step时的loss: 0.6938691139221191\n",
      "第62轮第1200训练step时的loss: 0.6908635497093201\n",
      "第62轮整体测试集上的Loss: 0.6929428419937912\n",
      "第62轮整体测试集上的Accuracy: 0.5035\n",
      "-------第 63 轮训练开始-------\n",
      "第63轮第100训练step时的loss: 0.6933334469795227\n",
      "第63轮第200训练step时的loss: 0.700413167476654\n",
      "第63轮第300训练step时的loss: 0.6818901300430298\n",
      "第63轮第400训练step时的loss: 0.6908572316169739\n",
      "第63轮第500训练step时的loss: 0.6909549236297607\n",
      "第63轮第600训练step时的loss: 0.6929020881652832\n",
      "第63轮第700训练step时的loss: 0.6954501867294312\n",
      "第63轮第800训练step时的loss: 0.7031343579292297\n",
      "第63轮第900训练step时的loss: 0.6991877555847168\n",
      "第63轮第1000训练step时的loss: 0.6984819173812866\n",
      "第63轮第1100训练step时的loss: 0.6993476152420044\n",
      "第63轮第1200训练step时的loss: 0.6869522929191589\n",
      "第63轮整体测试集上的Loss: 0.6929433614949555\n",
      "第63轮整体测试集上的Accuracy: 0.5037\n",
      "-------第 64 轮训练开始-------\n",
      "第64轮第100训练step时的loss: 0.7011734843254089\n",
      "第64轮第200训练step时的loss: 0.6983661651611328\n",
      "第64轮第300训练step时的loss: 0.6944282650947571\n",
      "第64轮第400训练step时的loss: 0.6854265332221985\n",
      "第64轮第500训练step时的loss: 0.6857339143753052\n",
      "第64轮第600训练step时的loss: 0.695297122001648\n",
      "第64轮第700训练step时的loss: 0.685683012008667\n",
      "第64轮第800训练step时的loss: 0.7110023498535156\n",
      "第64轮第900训练step时的loss: 0.6945434212684631\n",
      "第64轮第1000训练step时的loss: 0.7056140899658203\n",
      "第64轮第1100训练step时的loss: 0.7047300338745117\n",
      "第64轮第1200训练step时的loss: 0.6938566565513611\n",
      "第64轮整体测试集上的Loss: 0.6929422746239325\n",
      "第64轮整体测试集上的Accuracy: 0.5078\n",
      "-------第 65 轮训练开始-------\n",
      "第65轮第100训练step时的loss: 0.6872854232788086\n",
      "第65轮第200训练step时的loss: 0.6974535584449768\n",
      "第65轮第300训练step时的loss: 0.679976224899292\n",
      "第65轮第400训练step时的loss: 0.7057788968086243\n",
      "第65轮第500训练step时的loss: 0.6943587064743042\n",
      "第65轮第600训练step时的loss: 0.682511568069458\n",
      "第65轮第700训练step时的loss: 0.6788435578346252\n",
      "第65轮第800训练step时的loss: 0.674898624420166\n",
      "第65轮第900训练step时的loss: 0.6813089847564697\n",
      "第65轮第1000训练step时的loss: 0.7016283273696899\n",
      "第65轮第1100训练step时的loss: 0.6922117471694946\n",
      "第65轮第1200训练step时的loss: 0.7036589980125427\n",
      "第65轮整体测试集上的Loss: 0.6929368416321349\n",
      "第65轮整体测试集上的Accuracy: 0.5123\n",
      "-------第 66 轮训练开始-------\n",
      "第66轮第100训练step时的loss: 0.6846277713775635\n",
      "第66轮第200训练step时的loss: 0.6940208673477173\n",
      "第66轮第300训练step时的loss: 0.7014645338058472\n",
      "第66轮第400训练step时的loss: 0.6920591592788696\n",
      "第66轮第500训练step时的loss: 0.6942957043647766\n",
      "第66轮第600训练step时的loss: 0.6896622776985168\n",
      "第66轮第700训练step时的loss: 0.6869599223136902\n",
      "第66轮第800训练step时的loss: 0.6926167011260986\n",
      "第66轮第900训练step时的loss: 0.6898832321166992\n",
      "第66轮第1000训练step时的loss: 0.703461766242981\n",
      "第66轮第1100训练step时的loss: 0.6921496391296387\n",
      "第66轮第1200训练step时的loss: 0.7103609442710876\n",
      "第66轮整体测试集上的Loss: 0.6929330037908213\n",
      "第66轮整体测试集上的Accuracy: 0.5107\n",
      "-------第 67 轮训练开始-------\n",
      "第67轮第100训练step时的loss: 0.698596179485321\n",
      "第67轮第200训练step时的loss: 0.6943278312683105\n",
      "第67轮第300训练step时的loss: 0.6906846761703491\n",
      "第67轮第400训练step时的loss: 0.6936037540435791\n",
      "第67轮第500训练step时的loss: 0.6848158836364746\n",
      "第67轮第600训练step时的loss: 0.6815930008888245\n",
      "第67轮第700训练step时的loss: 0.684592604637146\n",
      "第67轮第800训练step时的loss: 0.6881721615791321\n",
      "第67轮第900训练step时的loss: 0.6941333413124084\n",
      "第67轮第1000训练step时的loss: 0.6938272714614868\n",
      "第67轮第1100训练step时的loss: 0.6984188556671143\n",
      "第67轮第1200训练step时的loss: 0.6869078278541565\n",
      "第67轮整体测试集上的Loss: 0.6929261495943413\n",
      "第67轮整体测试集上的Accuracy: 0.5078\n",
      "-------第 68 轮训练开始-------\n",
      "第68轮第100训练step时的loss: 0.7060530185699463\n",
      "第68轮第200训练step时的loss: 0.6979408860206604\n",
      "第68轮第300训练step时的loss: 0.6876223683357239\n",
      "第68轮第400训练step时的loss: 0.6943567395210266\n",
      "第68轮第500训练step时的loss: 0.6957374811172485\n",
      "第68轮第600训练step时的loss: 0.6842437982559204\n",
      "第68轮第700训练step时的loss: 0.6901611685752869\n",
      "第68轮第800训练step时的loss: 0.7015636563301086\n",
      "第68轮第900训练step时的loss: 0.6840484738349915\n",
      "第68轮第1000训练step时的loss: 0.6991699934005737\n",
      "第68轮第1100训练step时的loss: 0.7130343914031982\n",
      "第68轮第1200训练step时的loss: 0.7012456655502319\n",
      "第68轮整体测试集上的Loss: 0.6929270011200085\n",
      "第68轮整体测试集上的Accuracy: 0.5109\n",
      "-------第 69 轮训练开始-------\n",
      "第69轮第100训练step时的loss: 0.6903688907623291\n",
      "第69轮第200训练step时的loss: 0.6870699524879456\n",
      "第69轮第300训练step时的loss: 0.6956353187561035\n",
      "第69轮第400训练step时的loss: 0.6979880928993225\n",
      "第69轮第500训练step时的loss: 0.7006057500839233\n",
      "第69轮第600训练step时的loss: 0.6778954267501831\n",
      "第69轮第700训练step时的loss: 0.6855490803718567\n",
      "第69轮第800训练step时的loss: 0.6976967453956604\n",
      "第69轮第900训练step时的loss: 0.6956428289413452\n",
      "第69轮第1000训练step时的loss: 0.7007123827934265\n",
      "第69轮第1100训练step时的loss: 0.6850220561027527\n",
      "第69轮第1200训练step时的loss: 0.6849645376205444\n",
      "第69轮整体测试集上的Loss: 0.6929169936401168\n",
      "第69轮整体测试集上的Accuracy: 0.522\n",
      "-------第 70 轮训练开始-------\n",
      "第70轮第100训练step时的loss: 0.6895509958267212\n",
      "第70轮第200训练step时的loss: 0.6958234310150146\n",
      "第70轮第300训练step时的loss: 0.6898173093795776\n",
      "第70轮第400训练step时的loss: 0.6838183403015137\n",
      "第70轮第500训练step时的loss: 0.6764431595802307\n",
      "第70轮第600训练step时的loss: 0.6921989321708679\n",
      "第70轮第700训练step时的loss: 0.6954131722450256\n",
      "第70轮第800训练step时的loss: 0.7020304799079895\n",
      "第70轮第900训练step时的loss: 0.7041990756988525\n",
      "第70轮第1000训练step时的loss: 0.6950345039367676\n",
      "第70轮第1100训练step时的loss: 0.6981696486473083\n",
      "第70轮第1200训练step时的loss: 0.6964864730834961\n",
      "第70轮整体测试集上的Loss: 0.6929197489969678\n",
      "第70轮整体测试集上的Accuracy: 0.5008\n",
      "-------第 71 轮训练开始-------\n",
      "第71轮第100训练step时的loss: 0.6973789930343628\n",
      "第71轮第200训练step时的loss: 0.6960723400115967\n",
      "第71轮第300训练step时的loss: 0.6904835104942322\n",
      "第71轮第400训练step时的loss: 0.6915791630744934\n",
      "第71轮第500训练step时的loss: 0.6915369033813477\n",
      "第71轮第600训练step时的loss: 0.6906880736351013\n",
      "第71轮第700训练step时的loss: 0.6947622895240784\n",
      "第71轮第800训练step时的loss: 0.6961202621459961\n",
      "第71轮第900训练step时的loss: 0.6928094029426575\n",
      "第71轮第1000训练step时的loss: 0.692876398563385\n",
      "第71轮第1100训练step时的loss: 0.691656231880188\n",
      "第71轮第1200训练step时的loss: 0.6927993297576904\n",
      "第71轮整体测试集上的Loss: 0.6929227079094296\n",
      "第71轮整体测试集上的Accuracy: 0.5051\n",
      "-------第 72 轮训练开始-------\n",
      "第72轮第100训练step时的loss: 0.6953977346420288\n",
      "第72轮第200训练step时的loss: 0.6963061690330505\n",
      "第72轮第300训练step时的loss: 0.6860216856002808\n",
      "第72轮第400训练step时的loss: 0.6886374354362488\n",
      "第72轮第500训练step时的loss: 0.6937123537063599\n",
      "第72轮第600训练step时的loss: 0.6861252188682556\n",
      "第72轮第700训练step时的loss: 0.6854192018508911\n",
      "第72轮第800训练step时的loss: 0.6820917129516602\n",
      "第72轮第900训练step时的loss: 0.6910006403923035\n",
      "第72轮第1000训练step时的loss: 0.6992796659469604\n",
      "第72轮第1100训练step时的loss: 0.6811517477035522\n",
      "第72轮第1200训练step时的loss: 0.6879755854606628\n",
      "第72轮整体测试集上的Loss: 0.692926443548093\n",
      "第72轮整体测试集上的Accuracy: 0.5111\n",
      "-------第 73 轮训练开始-------\n",
      "第73轮第100训练step时的loss: 0.6872009634971619\n",
      "第73轮第200训练step时的loss: 0.6993183493614197\n",
      "第73轮第300训练step时的loss: 0.6941680908203125\n",
      "第73轮第400训练step时的loss: 0.6827691793441772\n",
      "第73轮第500训练step时的loss: 0.6976912617683411\n",
      "第73轮第600训练step时的loss: 0.7014833092689514\n",
      "第73轮第700训练step时的loss: 0.6865481734275818\n",
      "第73轮第800训练step时的loss: 0.6999539732933044\n",
      "第73轮第900训练step时的loss: 0.6936334371566772\n",
      "第73轮第1000训练step时的loss: 0.6849803328514099\n",
      "第73轮第1100训练step时的loss: 0.6953317523002625\n",
      "第73轮第1200训练step时的loss: 0.7068079113960266\n",
      "第73轮整体测试集上的Loss: 0.6929301513934035\n",
      "第73轮整体测试集上的Accuracy: 0.5047\n",
      "-------第 74 轮训练开始-------\n",
      "第74轮第100训练step时的loss: 0.6889222860336304\n",
      "第74轮第200训练step时的loss: 0.6784104704856873\n",
      "第74轮第300训练step时的loss: 0.702345609664917\n",
      "第74轮第400训练step时的loss: 0.6927006244659424\n",
      "第74轮第500训练step时的loss: 0.6893103718757629\n",
      "第74轮第600训练step时的loss: 0.6942114233970642\n",
      "第74轮第700训练step时的loss: 0.7018321752548218\n",
      "第74轮第800训练step时的loss: 0.6944226026535034\n",
      "第74轮第900训练step时的loss: 0.7040395736694336\n",
      "第74轮第1000训练step时的loss: 0.6894374489784241\n",
      "第74轮第1100训练step时的loss: 0.6973879933357239\n",
      "第74轮第1200训练step时的loss: 0.6775491237640381\n",
      "第74轮整体测试集上的Loss: 0.6929253594729112\n",
      "第74轮整体测试集上的Accuracy: 0.5056\n",
      "-------第 75 轮训练开始-------\n",
      "第75轮第100训练step时的loss: 0.6848276853561401\n",
      "第75轮第200训练step时的loss: 0.6945509314537048\n",
      "第75轮第300训练step时的loss: 0.6984642744064331\n",
      "第75轮第400训练step时的loss: 0.6928374767303467\n",
      "第75轮第500训练step时的loss: 0.685042142868042\n",
      "第75轮第600训练step时的loss: 0.6956086158752441\n",
      "第75轮第700训练step时的loss: 0.6933636665344238\n",
      "第75轮第800训练step时的loss: 0.6999001502990723\n",
      "第75轮第900训练step时的loss: 0.6903204917907715\n",
      "第75轮第1000训练step时的loss: 0.7003666162490845\n",
      "第75轮第1100训练step时的loss: 0.6917732357978821\n",
      "第75轮第1200训练step时的loss: 0.6866955161094666\n",
      "第75轮整体测试集上的Loss: 0.6929183782114942\n",
      "第75轮整体测试集上的Accuracy: 0.5098\n",
      "-------第 76 轮训练开始-------\n",
      "第76轮第100训练step时的loss: 0.6939957141876221\n",
      "第76轮第200训练step时的loss: 0.6813302636146545\n",
      "第76轮第300训练step时的loss: 0.6929630041122437\n",
      "第76轮第400训练step时的loss: 0.685449481010437\n",
      "第76轮第500训练step时的loss: 0.694943904876709\n",
      "第76轮第600训练step时的loss: 0.7030923962593079\n",
      "第76轮第700训练step时的loss: 0.7011638879776001\n",
      "第76轮第800训练step时的loss: 0.6935899257659912\n",
      "第76轮第900训练step时的loss: 0.6970661878585815\n",
      "第76轮第1000训练step时的loss: 0.683256983757019\n",
      "第76轮第1100训练step时的loss: 0.6986462473869324\n",
      "第76轮第1200训练step时的loss: 0.6979390978813171\n",
      "第76轮整体测试集上的Loss: 0.6929115027681938\n",
      "第76轮整体测试集上的Accuracy: 0.5213\n",
      "-------第 77 轮训练开始-------\n",
      "第77轮第100训练step时的loss: 0.7005676627159119\n",
      "第77轮第200训练step时的loss: 0.6860536336898804\n",
      "第77轮第300训练step时的loss: 0.6910022497177124\n",
      "第77轮第400训练step时的loss: 0.6698747277259827\n",
      "第77轮第500训练step时的loss: 0.6913046836853027\n",
      "第77轮第600训练step时的loss: 0.6950640678405762\n",
      "第77轮第700训练step时的loss: 0.6849167943000793\n",
      "第77轮第800训练step时的loss: 0.6963823437690735\n",
      "第77轮第900训练step时的loss: 0.6972548365592957\n",
      "第77轮第1000训练step时的loss: 0.6960517764091492\n",
      "第77轮第1100训练step时的loss: 0.6907797455787659\n",
      "第77轮第1200训练step时的loss: 0.7032828330993652\n",
      "第77轮整体测试集上的Loss: 0.6929061590181245\n",
      "第77轮整体测试集上的Accuracy: 0.5107\n",
      "-------第 78 轮训练开始-------\n",
      "第78轮第100训练step时的loss: 0.6932393908500671\n",
      "第78轮第200训练step时的loss: 0.6864214539527893\n",
      "第78轮第300训练step时的loss: 0.6867752075195312\n",
      "第78轮第400训练step时的loss: 0.7009051442146301\n",
      "第78轮第500训练step时的loss: 0.6772012710571289\n",
      "第78轮第600训练step时的loss: 0.7104318141937256\n",
      "第78轮第700训练step时的loss: 0.6837719678878784\n",
      "第78轮第800训练step时的loss: 0.7000418901443481\n",
      "第78轮第900训练step时的loss: 0.6895335912704468\n",
      "第78轮第1000训练step时的loss: 0.6824491024017334\n",
      "第78轮第1100训练step时的loss: 0.6907634735107422\n",
      "第78轮第1200训练step时的loss: 0.6948045492172241\n",
      "第78轮整体测试集上的Loss: 0.6928865568030241\n",
      "第78轮整体测试集上的Accuracy: 0.5195\n",
      "-------第 79 轮训练开始-------\n",
      "第79轮第100训练step时的loss: 0.6854547262191772\n",
      "第79轮第200训练step时的loss: 0.6833115816116333\n",
      "第79轮第300训练step时的loss: 0.6927610635757446\n",
      "第79轮第400训练step时的loss: 0.7019891142845154\n",
      "第79轮第500训练step时的loss: 0.694744348526001\n",
      "第79轮第600训练step时的loss: 0.6971451640129089\n",
      "第79轮第700训练step时的loss: 0.6860096454620361\n",
      "第79轮第800训练step时的loss: 0.6788429021835327\n",
      "第79轮第900训练step时的loss: 0.6935672163963318\n",
      "第79轮第1000训练step时的loss: 0.6900179982185364\n",
      "第79轮第1100训练step时的loss: 0.7096214294433594\n",
      "第79轮第1200训练step时的loss: 0.7053807973861694\n",
      "第79轮整体测试集上的Loss: 0.6928743470275182\n",
      "第79轮整体测试集上的Accuracy: 0.5143\n",
      "-------第 80 轮训练开始-------\n",
      "第80轮第100训练step时的loss: 0.6859090328216553\n",
      "第80轮第200训练step时的loss: 0.6819924116134644\n",
      "第80轮第300训练step时的loss: 0.6785877346992493\n",
      "第80轮第400训练step时的loss: 0.6864094138145447\n",
      "第80轮第500训练step时的loss: 0.7010480761528015\n",
      "第80轮第600训练step时的loss: 0.6967584490776062\n",
      "第80轮第700训练step时的loss: 0.6988886594772339\n",
      "第80轮第800训练step时的loss: 0.6950773596763611\n",
      "第80轮第900训练step时的loss: 0.6918776631355286\n",
      "第80轮第1000训练step时的loss: 0.6956689357757568\n",
      "第80轮第1100训练step时的loss: 0.6979529857635498\n",
      "第80轮第1200训练step时的loss: 0.6890217065811157\n",
      "第80轮整体测试集上的Loss: 0.6928624923794697\n",
      "第80轮整体测试集上的Accuracy: 0.5152\n",
      "-------第 81 轮训练开始-------\n",
      "第81轮第100训练step时的loss: 0.702620804309845\n",
      "第81轮第200训练step时的loss: 0.6970285773277283\n",
      "第81轮第300训练step时的loss: 0.6805262565612793\n",
      "第81轮第400训练step时的loss: 0.6938342452049255\n",
      "第81轮第500训练step时的loss: 0.6836603879928589\n",
      "第81轮第600训练step时的loss: 0.686939001083374\n",
      "第81轮第700训练step时的loss: 0.6983333230018616\n",
      "第81轮第800训练step时的loss: 0.6846869587898254\n",
      "第81轮第900训练step时的loss: 0.6946589946746826\n",
      "第81轮第1000训练step时的loss: 0.7010542750358582\n",
      "第81轮第1100训练step时的loss: 0.6989073157310486\n",
      "第81轮第1200训练step时的loss: 0.7027058601379395\n",
      "第81轮整体测试集上的Loss: 0.692859862291028\n",
      "第81轮整体测试集上的Accuracy: 0.5123\n",
      "-------第 82 轮训练开始-------\n",
      "第82轮第100训练step时的loss: 0.6806353330612183\n",
      "第82轮第200训练step时的loss: 0.6912292242050171\n",
      "第82轮第300训练step时的loss: 0.6791589260101318\n",
      "第82轮第400训练step时的loss: 0.6893634796142578\n",
      "第82轮第500训练step时的loss: 0.6848775744438171\n",
      "第82轮第600训练step时的loss: 0.6722033023834229\n",
      "第82轮第700训练step时的loss: 0.7015671133995056\n",
      "第82轮第800训练step时的loss: 0.6973563432693481\n",
      "第82轮第900训练step时的loss: 0.680211067199707\n",
      "第82轮第1000训练step时的loss: 0.6934165358543396\n",
      "第82轮第1100训练step时的loss: 0.6974299550056458\n",
      "第82轮第1200训练step时的loss: 0.7144232988357544\n",
      "第82轮整体测试集上的Loss: 0.6928582401541973\n",
      "第82轮整体测试集上的Accuracy: 0.5046\n",
      "-------第 83 轮训练开始-------\n",
      "第83轮第100训练step时的loss: 0.6909459829330444\n",
      "第83轮第200训练step时的loss: 0.6811671853065491\n",
      "第83轮第300训练step时的loss: 0.6901387572288513\n",
      "第83轮第400训练step时的loss: 0.6925650835037231\n",
      "第83轮第500训练step时的loss: 0.6971509456634521\n",
      "第83轮第600训练step时的loss: 0.690426230430603\n",
      "第83轮第700训练step时的loss: 0.693528413772583\n",
      "第83轮第800训练step时的loss: 0.693819522857666\n",
      "第83轮第900训练step时的loss: 0.692337155342102\n",
      "第83轮第1000训练step时的loss: 0.688067615032196\n"
     ]
    }
   ],
   "source": [
    "train_step_loss = []\n",
    "valid_step_loss = []\n",
    "train_epoch_loss = []\n",
    "valid_epoch_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-------第 {} 轮训练开始-------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    myModel.train()\n",
    "    step = 0\n",
    "    for data in trainloader:\n",
    "        trData, labels = data\n",
    "        outputs = myModel(trData) # 求模型的输出\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        loss = loss_fn(outputs, labels)  # 求loss\n",
    "        train_step_loss.append(loss.item())\n",
    "        step += 1\n",
    "\n",
    "        if (step%100 ==0):\n",
    "            print(f'第{i+1}轮第{step}训练step时的loss: {loss.item()}')\n",
    "\n",
    "\n",
    "        # 优化器优化模型\n",
    "        loss.backward()       # 求梯度\n",
    "        optimizer.step()      # 更新参数\n",
    "        \n",
    "    train_epoch_loss.append(np.average(train_step_loss))\n",
    "\n",
    "    # 测试步骤开始\n",
    "    myModel.eval()\n",
    "    total_accuracy = 0        # 每一轮总的精确度\n",
    "    with torch.no_grad():     # 不求梯度，不更新参数\n",
    "        for data in testloader:\n",
    "            teData, teLabels = data\n",
    "            outputs = myModel(teData)\n",
    "            loss = loss_fn(outputs, teLabels)\n",
    "            valid_step_loss.append(loss.item())\n",
    "            total_accuracy = total_accuracy + correct_num(teLabels,outputs)\n",
    "\n",
    "    valid_epoch_loss.append(np.average(valid_step_loss))\n",
    "    print(f\"第{i+1}轮整体测试集上的Loss: {valid_epoch_loss[-1]}\")\n",
    "    print(f\"第{i+1}轮整体测试集上的Accuracy: {total_accuracy/len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
